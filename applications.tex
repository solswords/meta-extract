% \begin{comment}
% [Old comment] SOL will write this (perhaps including an application
%   from Centaur)
% --- Sol, is this done now?
% \end{comment}

% Since we used upper-case for subsections in intro.tex, for
% consistency let's use them in this file, too.  (But we could use
% lower-case in both; fine with me either way.)

\begin{comment}
  I was thinking of this as some examples readers could look at to
  show how meta-extract is used in practice, but now that we have the
  examples from the previous section maybe that shouldn't be the
  focus.  Instead, maybe we really want to say what the most important
  uses of it so far have been, and just show that it really is useful
  in building sophisticated tools.  So, de-emphasize the just-expand
  utility and spend a bit more time on GL?

  [Matt, replacing what I wrote in my 12/28 email] I'm probably not
  understanding your point, since to me, ``how meta-extract is used in
  practice'' and ``most important uses of it so far'' are almost the
  same.  Maybe your point was that it's better to focus on the most
  {\em important} uses than it is to focus on the practicality of a
  wide {\em range} of uses.  If so, I guess I sort of agree if I had
  to choose; but I think both are really good.  And really, the
  section already fleshes out the range of uses while mentioning some
  important ones, notably GL.  Anyhow, I'll probably be happy with
  whatever you'd like to do here.  In particular, if you care to
  provide a bit more detail about how meta-extract supports GL, that
  would be fine; but I can live with what we already have, too.  Oh,
  and it looks like you might be concerned about overlap between this
  section and the previous two sections, but I think each section
  makes its own contribution: Section~\ref{sec:meta-extract} shows how
  meta-extract works, Section~\ref{sec:user} shows your
  bad-guy-based tools, and this section shows wide applicability,
  sometimes providing important capabilities.
\end{comment}

\subsection{Just-expand Utility}

The community book ``clause-processors/just-expand.lisp'' provides a
very simple illustration of the usage of meta-extract.  It uses
meta-extract only to look up a formula for a function so that it can
expand that definition.  The core functionality is in the function
\texttt{expand-this-term}.  That function looks up the rule, or the
definition of the leading function symbol if an explicit rule is not
given, using \texttt{meta-extract-formula}.  It then essentially
applies that rule as an unconditional rewrite.  First it ensures that
its body is of the form
\begin{lstlisting}
 (equal <$\mathit{lhs}$> <$\mathit{rhs}$>).
\end{lstlisting}
If so, it tries to unify the input term with $\mathit{lhs}$, obtaining
a unifying substitution $\sigma$ if successful, and returns the
substitution of $\sigma$ into $\mathit{rhs}$.  This procedure is proven
correct under a meta-extract hypothesis, which is used to reason that
the formula obtained by looking up the rule is a theorem.

\texttt{Expand-this-term} is used to define two clause processors and
a meta rule, each of which is proven correct using meta-extract
hypotheses.  The first clause processor, \texttt{just-expand-cp},
applies \texttt{expand-this-term} to all subterms of the goal clause
that match some user-provided patterns.  The second clause processor,
\texttt{expand-marked-cp}, looks for calls of an identity function
\texttt{expand-me} and expands the term contained immediately inside
each such call, removing the \texttt{expand-me} call itself.  The meta
rule, \texttt{expand-marked-meta}, triggers on \texttt{expand-me} and
similarly expands the contained terms.

\begin{comment}
  Sol, it would be interesting to know why, for the two
  clause-processors above, you used meta-extract rather than just
  making computed hints (or override hints) that :expand suitable
  terms.  I {\em do} see why computed hints wouldn't suffice if you
  were talking about metafunctions instead of clause-processors, since
  terms to be expanded can arise during rewriting.

  [Sol] One place it's used is in a hint that inducts and then
  immediately expands the calls of the given function in the induction
  conclusion but not the induction hyps.  I'm not sure how deep we
  need to go with motivation for each of these so I'm not sure if I
  should say anything about it in the paper.

  [Matt] Hmmm, but your description doesn't make it clear to me where
  the expand-me calls come from when using expand-marked-meta to
  expand certain terms produced by induction.  I agree with your
  general uncertainty about the value of saying much about
  expand-marked-meta, but as a reader I'd like to get just a quick
  sense of the flow that results in its application.
\end{comment}

\subsection{Rewrite-bounds}

The community book ``centaur/misc/bound-rewriter.lisp'' provides a
tool for solving certain inequalities: it replaces subterms of an
inequality with known bounds if those subterms are in monotonic
positions.  For example, the term $a-b$ monotonically decreases as $b$
increases, so if we wish to prove $c<a-b$ and we know $B \geq b$, then
it suffices to prove $c<a-B$.  While this example would be easily
handled by ACL2's linear arithmetic solver, there are problems that
the bound rewriter can handle easily that overwhelm ACL2's nonlinear
solver -- e.g.,
\begin{verbatim}
(implies (and (rationalp a) (rationalp b) (rationalp c)
              (<= 0 a) (<= 0 b) (<= 1 c)
              (<= a 10) (<= b 20) (<= c 30))
         (<= (+ (* a b c) (* a b) (* b c) (* a c))
             (+ (* 10 20 30) (* 10 20) (* 20 30) (* 10 30))))
\end{verbatim}
On this formula, a \texttt{:nonlinearp t} hint causes ACL2 to hang indefinitely, while the hint
\begin{verbatim}
(rewrite-bounds ((<= a 10)
                 (<= b 20)
                 (<= c 30)))
\end{verbatim}
solves it instantaneously, by replacing upper-boundable occurrences of
\texttt{a} by 10, \texttt{b} by 20, and \texttt{c} by 30.  The same
results are obtained --- a quick proof using {\tt rewrite-bounds} but
an indefinite hang using nonlinear arithmetic --- if the arithmetic
expression on the last line of the theorem is replaced by its value,
7100.

The bound rewriter tool is implemented as a meta rule and uses
meta-extract extensively.  To determine which subterms are in
monotonic positions, it uses type-set reasoning to determine the signs
of subterms.  For example, $a \cdot b$ increases as $b$ increases if
$a$ is nonnegative and decreases as $b$ increases if $a$ is
nonpositive; if we can't (weakly) determine the sign of $a$, then we
can't replace $b$ or any subterm with a bound.  To determine whether a
proposed bound of a subterm is (contextually) true, it uses
\texttt{mfc-relieve-hyp} to show it by rewriting, and if that fails,
\texttt{mfc-ap} to show it by linear arithmetic reasoning.  The
correctness of these uses of ACL2 reasoning utilities are justified by
meta-extract-contextual-fact hypotheses.

\subsection{Others}

Several other clause processors in the community books use
meta-extract solely to be able to extract a formula from the world
(using \texttt{meta-extract-formula}) and assume it to be true.  For
example, ``clause-processors/witness-cp.lisp'' provides a framework
for reasoning about quantification (see
\href{http://www.cs.utexas.edu/users/moore/acl2/manuals/current/manual/index.html?topic=ACL2\_\_\_\_WITNESS-CP}{\underline{witness-cp}}); it uses
\texttt{meta-extract-formula} to look up a stored fact showing that a
term representing a universal quantification implies any instance
of the quantified formula.  Another book,
``clause-processors/replace-equalities.lisp'' provides a tool for
replacing known equalities in ways that aren't accessible to the
rewriter, e.g., replacing a variable with a term.  For example, the
following is not a valid rewrite rule because its left-hand side is a variable,
but it could be a good replace-equalities rule:
\begin{verbatim}
 (implies (unify-ok pattern term alist)
          (equal term
                 (subsitute pattern (unify-subst pattern term alist))))
\end{verbatim}

\begin{comment}
Above, ``subsitute'' looks like a typo.  Probably you meant
``substitute'', but probably, you really meant
``substitute-into-term''.  When I read this I thought it said
``substitute'', and I thought it was weird to use a generic sort of
list utility to create a term.  So I looked at
clause-processors/replace-equalities.lisp and found
substitute-into-term.  Maybe the reader could do that too, but I very
slightly prefer just using substitute-into-term.  You get to decide --
but of course something needs to be done about the typo,
``subsitute''.
\end{comment}

A meta rule for context-sensitive rewriting, accomplishing something
similar to Greve's ``Nary'' framework \cite{greve06}, is defined in
``centaur/misc/context-rw.lisp'' (see
\href{http://www.cs.utexas.edu/users/moore/acl2/manuals/current/manual/index.html?topic=ACL2\_\_\_\_CONTEXTUAL-REWRITING}{\underline{contextual-rewriting}}).
It uses meta-extract to allow it to
trust \texttt{mfc-relieve-hyp}, \texttt{mfc-rw+}, and
\href{http://www.cs.utexas.edu/users/moore/acl2/manuals/current/manual/index.html?topic=ACL2\_\_\_\_MAGIC-EV-FNCALL}{\underline{\tt magic-ev-fncall}}.

The
\href{http://www.cs.utexas.edu/users/moore/acl2/manuals/current/manual/index.html?topic=ACL2\_\_\_\_GL}{\underline{GL}}
framework for bit-level symbolic execution~\cite{gl-diss,
  bit-blasting-GL} uses meta-extract to look up function definitions
and rewrite rules from the world and to evaluate ground terms using
\texttt{magic-ev-fncall}.
